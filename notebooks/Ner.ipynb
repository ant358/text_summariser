{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# import json \n",
    "import glob\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 829/829 [00:00<00:00, 81.0kB/s]\n",
      "Downloading: 100%|██████████| 433M/433M [00:24<00:00, 17.7MB/s] \n",
      "Downloading: 100%|██████████| 213k/213k [00:00<00:00, 715kB/s] \n",
      "Downloading: 100%|██████████| 2.00/2.00 [00:00<00:00, 988B/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 37.4kB/s]\n",
      "Downloading: 100%|██████████| 59.0/59.0 [00:00<00:00, 14.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained('dslim/bert-base-NER')\n",
    "tokenizer = AutoTokenizer.from_pretrained('dslim/bert-base-NER')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('ner', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'Lie', 'score': 0.6306365132331848, 'entity': 'B-ORG', 'index': 44, 'start': 214, 'end': 217}, {'word': '##ge', 'score': 0.27894917130470276, 'entity': 'I-ORG', 'index': 45, 'start': 217, 'end': 219}, {'word': 'Ba', 'score': 0.7687879800796509, 'entity': 'B-ORG', 'index': 47, 'start': 220, 'end': 222}, {'word': '##sto', 'score': 0.48457035422325134, 'entity': 'I-ORG', 'index': 48, 'start': 222, 'end': 225}, {'word': '##gne', 'score': 0.7429560422897339, 'entity': 'I-ORG', 'index': 49, 'start': 225, 'end': 228}, {'word': 'Lie', 'score': 0.4995739459991455, 'entity': 'B-ORG', 'index': 51, 'start': 229, 'end': 232}, {'word': 'Bernard', 'score': 0.9997014403343201, 'entity': 'B-PER', 'index': 80, 'start': 340, 'end': 347}, {'word': 'Hi', 'score': 0.9997100234031677, 'entity': 'I-PER', 'index': 81, 'start': 348, 'end': 350}, {'word': '##na', 'score': 0.9567268490791321, 'entity': 'I-PER', 'index': 82, 'start': 350, 'end': 352}, {'word': '##ult', 'score': 0.9372967481613159, 'entity': 'I-PER', 'index': 83, 'start': 352, 'end': 355}, {'word': 'A', 'score': 0.638192892074585, 'entity': 'B-LOC', 'index': 150, 'start': 643, 'end': 644}, {'word': '##rden', 'score': 0.811643123626709, 'entity': 'B-LOC', 'index': 151, 'start': 644, 'end': 648}, {'word': '##nes', 'score': 0.6126875281333923, 'entity': 'I-LOC', 'index': 152, 'start': 648, 'end': 651}, {'word': 'La', 'score': 0.8937310576438904, 'entity': 'B-MISC', 'index': 163, 'start': 695, 'end': 697}, {'word': 'Do', 'score': 0.9381925463676453, 'entity': 'I-MISC', 'index': 164, 'start': 698, 'end': 700}, {'word': '##ye', 'score': 0.8319066166877747, 'entity': 'I-MISC', 'index': 165, 'start': 700, 'end': 702}, {'word': '##nne', 'score': 0.8719673156738281, 'entity': 'I-MISC', 'index': 166, 'start': 702, 'end': 705}, {'word': 'Hi', 'score': 0.9957519173622131, 'entity': 'B-PER', 'index': 239, 'start': 1002, 'end': 1004}, {'word': '##na', 'score': 0.6075025796890259, 'entity': 'I-PER', 'index': 240, 'start': 1004, 'end': 1006}, {'word': 'Lie', 'score': 0.5483028888702393, 'entity': 'B-LOC', 'index': 260, 'start': 1079, 'end': 1082}, {'word': '##ge', 'score': 0.34938499331474304, 'entity': 'I-ORG', 'index': 261, 'start': 1082, 'end': 1084}, {'word': 'Ba', 'score': 0.8442264795303345, 'entity': 'B-LOC', 'index': 263, 'start': 1085, 'end': 1087}, {'word': '##sto', 'score': 0.6529582142829895, 'entity': 'I-LOC', 'index': 264, 'start': 1087, 'end': 1090}, {'word': '##gne', 'score': 0.5592276453971863, 'entity': 'I-LOC', 'index': 265, 'start': 1090, 'end': 1093}, {'word': 'Lie', 'score': 0.9189809560775757, 'entity': 'B-LOC', 'index': 267, 'start': 1094, 'end': 1097}, {'word': '##ge', 'score': 0.47925910353660583, 'entity': 'I-LOC', 'index': 268, 'start': 1097, 'end': 1099}, {'word': 'Hi', 'score': 0.9993430376052856, 'entity': 'B-PER', 'index': 291, 'start': 1213, 'end': 1215}, {'word': '##na', 'score': 0.9306159019470215, 'entity': 'I-PER', 'index': 292, 'start': 1215, 'end': 1217}, {'word': '##ult', 'score': 0.8811274766921997, 'entity': 'I-PER', 'index': 293, 'start': 1217, 'end': 1220}, {'word': 'Tour', 'score': 0.9980332851409912, 'entity': 'B-MISC', 'index': 302, 'start': 1252, 'end': 1256}, {'word': 'de', 'score': 0.9984781742095947, 'entity': 'I-MISC', 'index': 303, 'start': 1257, 'end': 1259}, {'word': 'France', 'score': 0.9989230036735535, 'entity': 'I-MISC', 'index': 304, 'start': 1260, 'end': 1266}, {'word': 'Tour', 'score': 0.9970104694366455, 'entity': 'B-MISC', 'index': 331, 'start': 1376, 'end': 1380}, {'word': 'Monument', 'score': 0.9721497297286987, 'entity': 'B-MISC', 'index': 366, 'start': 1540, 'end': 1548}, {'word': 'Lie', 'score': 0.8287788033485413, 'entity': 'B-LOC', 'index': 375, 'start': 1576, 'end': 1579}, {'word': '##ge', 'score': 0.5036606192588806, 'entity': 'B-LOC', 'index': 376, 'start': 1579, 'end': 1581}, {'word': 'Ba', 'score': 0.9730474352836609, 'entity': 'B-LOC', 'index': 378, 'start': 1582, 'end': 1584}, {'word': '##sto', 'score': 0.6039937138557434, 'entity': 'I-LOC', 'index': 379, 'start': 1584, 'end': 1587}, {'word': '##gne', 'score': 0.7867857217788696, 'entity': 'I-LOC', 'index': 380, 'start': 1587, 'end': 1590}, {'word': 'Lie', 'score': 0.964655339717865, 'entity': 'B-LOC', 'index': 382, 'start': 1591, 'end': 1594}, {'word': '##ge', 'score': 0.5972497463226318, 'entity': 'I-LOC', 'index': 383, 'start': 1594, 'end': 1596}, {'word': 'Belgium', 'score': 0.9920306205749512, 'entity': 'B-LOC', 'index': 406, 'start': 1693, 'end': 1700}]\n"
     ]
    }
   ],
   "source": [
    "# small test\n",
    "text = \"\"\"The oversized snowflakes fell softly and silently, settling among the pines like a picturesque Christmas scene.\n",
    "By the roadside, spectators in heavy winter coats watched team cars and motorbikes struggle up one of Liege-Bastogne-Liege's countless climbs, tyres spinning in the slush as they pursued one man on a bike.\n",
    "It was April 1980 and Bernard Hinault, almost unrecognisable beneath a big red balaclava, slewed doggedly on, further into the lead, somehow remaining balanced on the two wheels beneath him.\n",
    "He was under such physical strain that he would do himself permanent damage. Pushing his body to its very limit, he raced through the Ardennes in search of victory in the race known as 'La Doyenne' - the old lady.\n",
    "So bad were the conditions that several of cycling's best riders collected their number from organisers and then never lined up.\n",
    "After just 70km of the 244km one-day race, 110 of the 174 entrants were already holed up in a hotel by the finish line. Only 21 completed the course. Hinault suffered frostbite.\n",
    "Rarely do you see such attrition in cycling, but Liege-Bastogne-Liege, which celebrates its 130th birthday on Sunday, has been making and breaking the toughest competitors for years.\n",
    "Hinault was 25. He had already won the Tour de France twice and would go on to win it a further three times, an icon of his sport in the making. His total of five Tour victories remains a joint record.\n",
    "But this was a different challenge - a long way from the searing heat and sunflowers of summer.\n",
    "One of the five prestigious 'Monument' one-day races in cycling, Liege-Bastogne-Liege is celebrated by many for being the very antithesis of the Tour.\n",
    "In the hills of east and south Belgium the peloton is stretched through thick, damp forest, over short, sharp climbs and across tricky, part-cobbled sections before landing back where it all began in Liege.\n",
    "\"[The race is] already hard, it's long, and when I won it was in very tough conditions, especially the snow,\" says Hinault, now aged 67.\n",
    "\"Yes, I considered quitting if the weather conditions persisted. We started having difficulties. It's difficult in Liege-Bastogne-Liege.\"\n",
    "Hinault's account of one of his greatest triumphs is characteristically taciturn. Tough conditions is a severe understatement. And in the racing he didn't have it all his own way, either.\n",
    "With around 91km to go, approaching the 500m Stockeu climb, Rudy Pevenage was two minutes 15 seconds ahead of Hinault and a small chasing group.\n",
    "Pevenage was one of the hard men of the spring classics. He was a Belgian with a big lead, in conditions many locals would feel only a Belgian could master.\n",
    "But even he did not finish a race that truly separated the men from the legends. 'Neige-Bastogne-Neige,' as it would be dubbed.\n",
    "On the next climb, a 500m ascent of the Haute Levee, Hinault and a small number of fellow pursuers caught up with Pevenage. Then Hinault launched his attack, bright red balaclava and thick blue gloves disappearing into the distance as his stunning acceleration left everybody behind.\n",
    "There were still 80km to go.\n",
    "\"\"\"\n",
    "ner_results = nlp(text, show_tokens=False)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>entity</th>\n",
       "      <th>index</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lie</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>44</td>\n",
       "      <td>214</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>##ge</td>\n",
       "      <td>0.278949</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>45</td>\n",
       "      <td>217</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ba</td>\n",
       "      <td>0.768788</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>47</td>\n",
       "      <td>220</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##sto</td>\n",
       "      <td>0.484570</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>48</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##gne</td>\n",
       "      <td>0.742956</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>49</td>\n",
       "      <td>225</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word     score entity  index  start  end\n",
       "0    Lie  0.630637  B-ORG     44    214  217\n",
       "1   ##ge  0.278949  I-ORG     45    217  219\n",
       "2     Ba  0.768788  B-ORG     47    220  222\n",
       "3  ##sto  0.484570  I-ORG     48    222  225\n",
       "4  ##gne  0.742956  I-ORG     49    225  228"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert ner_results to dataframe\n",
    "df = pd.DataFrame(ner_results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Liege', 'Bastogne']\n"
     ]
    }
   ],
   "source": [
    "# get the ORG entities\n",
    "locs = df[df['entity'].str.contains('-ORG')].copy()\n",
    "orgs = orgs[['word', 'entity']]\n",
    "\n",
    "# get the index of each B-ORG\n",
    "begin_index = orgs[orgs['entity'] == 'B-ORG'].index.tolist()\n",
    "# print(begin_index)\n",
    "# create a list to hold the words\n",
    "org_words = []\n",
    "\n",
    "for i in range(len(begin_index)):\n",
    "    if i < len(begin_index) - 1:\n",
    "        word_parts_list = orgs.loc[begin_index[i]: begin_index[i+1]-1, 'word'].tolist()\n",
    "        word = [''.join([x.strip('##') for x in word_parts_list])]\n",
    "        org_words.append(word[0])\n",
    "    else:\n",
    "        break\n",
    "print(org_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word entity\n",
      "10        A  B-LOC\n",
      "11   ##rden  B-LOC\n",
      "12    ##nes  I-LOC\n",
      "19      Lie  B-LOC\n",
      "21       Ba  B-LOC\n",
      "22    ##sto  I-LOC\n",
      "23    ##gne  I-LOC\n",
      "24      Lie  B-LOC\n",
      "25     ##ge  I-LOC\n",
      "34      Lie  B-LOC\n",
      "35     ##ge  B-LOC\n",
      "36       Ba  B-LOC\n",
      "37    ##sto  I-LOC\n",
      "38    ##gne  I-LOC\n",
      "39      Lie  B-LOC\n",
      "40     ##ge  I-LOC\n",
      "41  Belgium  B-LOC\n",
      "['A', 'rdennes', 'Lie', 'Bastogne', 'Liege', 'Lie', 'ge', 'Bastogne', 'Liege']\n"
     ]
    }
   ],
   "source": [
    "# get the ORG entities\n",
    "locs = df[df['entity'].str.contains('-LOC')].copy()\n",
    "locs = locs[['word', 'entity']]\n",
    "print(locs)\n",
    "\n",
    "# get the index of each B-ORG\n",
    "begin_index = locs[locs['entity'] == 'B-LOC'].index.tolist()\n",
    "# print(begin_index)\n",
    "# create a list to hold the words\n",
    "loc_words = []\n",
    "\n",
    "for i in range(len(begin_index)):\n",
    "    if i < len(begin_index) - 1:\n",
    "        word_parts_list = locs.loc[begin_index[i]: begin_index[i+1]-1, 'word'].tolist()\n",
    "        word = [''.join([x.strip('##') for x in word_parts_list])]\n",
    "        loc_words.append(word[0])\n",
    "    else:\n",
    "        break\n",
    "print(loc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word entity\n",
      "6   Bernard  B-PER\n",
      "7        Hi  I-PER\n",
      "8      ##na  I-PER\n",
      "9     ##ult  I-PER\n",
      "17       Hi  B-PER\n",
      "18     ##na  I-PER\n",
      "26       Hi  B-PER\n",
      "27     ##na  I-PER\n",
      "28    ##ult  I-PER\n",
      "['BernardHinault', 'Hina']\n"
     ]
    }
   ],
   "source": [
    "# get the ORG entities\n",
    "pers = df[df['entity'].str.contains('-PER')].copy()\n",
    "pers = pers[['word', 'entity']]\n",
    "print(pers)\n",
    "\n",
    "# get the index of each B-ORG\n",
    "begin_index = pers[pers['entity'] == 'B-PER'].index.tolist()\n",
    "# print(begin_index)\n",
    "# create a list to hold the words\n",
    "per_words = []\n",
    "\n",
    "for i in range(len(begin_index)):\n",
    "    if i < len(begin_index) - 1:\n",
    "        word_parts_list = pers.loc[begin_index[i]: begin_index[i+1]-1, 'word'].tolist()\n",
    "        word = [''.join([x.strip('##') for x in word_parts_list])]\n",
    "        per_words.append(word[0])\n",
    "    else:\n",
    "        break\n",
    "print(per_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word  entity\n",
      "13        La  B-MISC\n",
      "14        Do  I-MISC\n",
      "15      ##ye  I-MISC\n",
      "16     ##nne  I-MISC\n",
      "29      Tour  B-MISC\n",
      "30        de  I-MISC\n",
      "31    France  I-MISC\n",
      "32      Tour  B-MISC\n",
      "33  Monument  B-MISC\n",
      "['LaDoyenne', 'TourdeFrance', 'Tour']\n"
     ]
    }
   ],
   "source": [
    "# get the ORG entities\n",
    "misc = df[df['entity'].str.contains('-MISC')].copy()\n",
    "misc = misc[['word', 'entity']]\n",
    "print(misc)\n",
    "\n",
    "# get the index of each B-ORG\n",
    "begin_index = misc[misc['entity'] == 'B-MISC'].index.tolist()\n",
    "# print(begin_index)\n",
    "# create a list to hold the words\n",
    "misc_words = []\n",
    "\n",
    "for i in range(len(begin_index)):\n",
    "    if i < len(begin_index) - 1:\n",
    "        word_parts_list = misc.loc[begin_index[i]: begin_index[i+1]-1, 'word'].tolist()\n",
    "        word = [''.join([x.strip('##') for x in word_parts_list])]\n",
    "        misc_words.append(word[0])\n",
    "    else:\n",
    "        break\n",
    "print(misc_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../src/models/dslim/bert-base-NER\\\\tokenizer_config.json',\n",
       " '../src/models/dslim/bert-base-NER\\\\special_tokens_map.json',\n",
       " '../src/models/dslim/bert-base-NER\\\\vocab.txt',\n",
       " '../src/models/dslim/bert-base-NER\\\\added_tokens.json',\n",
       " '../src/models/dslim/bert-base-NER\\\\tokenizer.json')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model \n",
    "model.save_pretrained(\"../src/models/dslim/bert-base-NER\")\n",
    "# # save the tokenizer\n",
    "tokenizer.save_pretrained(\"../src/models/dslim/bert-base-NER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "492638d293504aedf19d0c409a33bc76a42a9110c8d7cf57e8499762db84f0ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('txt_sum_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
